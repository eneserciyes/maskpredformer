{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"data_prepared/train\"\n",
    "\n",
    "all_videos = [name for name in os.listdir(root)\n",
    "            if os.path.isdir(os.path.join(root, name))]\n",
    "all_videos.sort(key= lambda x: int(x.split('/')[-1].split('.')[0].split('_')[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sample = torch.load(os.path.join(root, all_videos[0], 'mask.pt')).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = np.memmap(os.path.join(root, 'masks.bin'), dtype='float16', mode='w+', shape=(len(all_videos), *mask_sample.shape))\n",
    "# for i, video in tqdm.tqdm(enumerate(all_videos), total=len(all_videos)):\n",
    "#     mask = torch.load(os.path.join(root, video, 'mask.pt')).numpy()\n",
    "#     fp[i] = mask\n",
    "#     fp.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemMapDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, length, t=22, c=49, h=160, w=240):\n",
    "        path = os.path.join(root, split, 'masks.bin')\n",
    "        self.fp = np.memmap(path, dtype='float16', mode='r', shape=(length, t, c, h, w))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.from_numpy(self.fp[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskPredDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, split):\n",
    "        self.data_path = os.path.join(data_root, split)\n",
    "        self.split = split\n",
    "\n",
    "        all_videos = [name for name in os.listdir(root)\n",
    "            if os.path.isdir(os.path.join(root, name))]\n",
    "        all_videos.sort(key= lambda x: int(x.split('/')[-1].split('.')[0].split('_')[-1]))\n",
    "        self.all_videos = all_videos\n",
    "\n",
    "        # all_masks = []\n",
    "        # for video in tqdm.tqdm(all_videos, postfix=\"Loading masks for split {}\".format(split)):\n",
    "        #     mask_path = os.path.join(self.data_path, video, \"mask.pt\")\n",
    "        #     mask = torch.load(mask_path)\n",
    "        #     all_masks.append(mask.float())\n",
    "        # self.all_masks = all_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mask_path = os.path.join(self.data_path, self.all_videos[idx], \"mask.pt\")\n",
    "        mask = torch.load(mask_path)\n",
    "        return mask.float()\n",
    "        # return self.all_masks[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mm = MemMapDataset(os.path.join(root, 'masks.bin'))\n",
    "dataloader_mm = torch.utils.data.DataLoader(dataset_mm, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "dataset = MaskPredDataset('data_prepared', 'train')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in tqdm.tqdm(dataloader_mm):\n",
    "    print(mask.shape)\n",
    "    mask = mask.to('cuda')\n",
    "    print(mask.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:52<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for mask in tqdm.tqdm(dataloader):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memmap Dataset one epoch read time\n",
    "# 2.27 normal\n",
    "# 1.16-1.08 with bs 4\n",
    "# 0.22 with torch.from_numpy\n",
    "\n",
    "# Normal Dataset one epoch read time\n",
    "# 1:52 with bs 4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maskpredformer",
   "language": "python",
   "name": "maskpredformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
