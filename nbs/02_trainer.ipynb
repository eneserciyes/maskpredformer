{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Trainer for MaskSimVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import lightning as pl\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from lightning.pytorch.utilities import grad_norm\n",
    "\n",
    "from maskpredformer.mask_simvp import MaskSimVP\n",
    "from maskpredformer.simvp_dataset import DLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MaskSimVPTrainer(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 in_shape, hid_S, hid_T, N_S, N_T, model_type,\n",
    "                 batch_size, lr, weight_decay, max_epochs,\n",
    "                 data_root):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = MaskSimVP(\n",
    "            in_shape, hid_S, hid_T, N_S, N_T, model_type\n",
    "        )\n",
    "        self.train_set = DLDataset(data_root, \"train\")\n",
    "        self.val_set = DLDataset(data_root, \"val\")\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_set, batch_size=self.hparams.batch_size, \n",
    "            num_workers=8, shuffle=True, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_set, batch_size=self.hparams.batch_size, \n",
    "            num_workers=8, shuffle=False, pin_memory=True\n",
    "        )\n",
    "\n",
    "    def step(self, x, y):\n",
    "        y_hat_logits = self.model(x)\n",
    "        assert y_hat_logits.shape == (y.shape[0], y.shape[1], 49, y.shape[3], y.shape[4]) \n",
    "        return y_hat_logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat_logits = self.step(x, y)\n",
    "        loss = self.criterion(y_hat_logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat_logits = self.step(x, y)\n",
    "        loss = self.criterion(y_hat_logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=self.hparams.lr, \n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer, max_lr=self.hparams.lr,\n",
    "            total_steps=self.hparams.max_epochs*len(self.train_dataloader()),\n",
    "            final_div_factor=1e4\n",
    "        )\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Video Callback\n",
    "\n",
    "> sample video callback to generate video samples during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SampleVideoCallback(pl.Callback):\n",
    "    def __init__(self, val_set):\n",
    "        super().__init__()\n",
    "        self.val_set = val_set\n",
    "\n",
    "    def apply_cm(self, x):\n",
    "        cm = plt.get_cmap()\n",
    "        norm = plt.Normalize(vmin=x.min(), vmax=x.max())\n",
    "        return cm(norm(x))[:, :, :3].transpose(2,0,1) \n",
    "\n",
    "    def generate_video(self, pl_module):\n",
    "        pl_module.eval()\n",
    "        sample_idx = random.randint(0, len(self.val_set)-1)\n",
    "        \n",
    "        x, y = self.val_set[sample_idx]\n",
    "        x = x.unsqueeze(0).to(pl_module.device)\n",
    "        y = y.unsqueeze(0).to(pl_module.device)\n",
    "\n",
    "        y_hat_logits = pl_module.step(x,y).squeeze(0) # (T, 49, H, W)\n",
    "        y_hat = torch.argmax(y_hat_logits, dim=1) # (T, H, W)\n",
    "\n",
    "        # convert to numpy\n",
    "        x = x.squeeze(0).cpu().numpy()\n",
    "        y = y.squeeze(0).cpu().numpy()\n",
    "        y_hat = y_hat.cpu().numpy()\n",
    "\n",
    "        gt_imgs = []\n",
    "        pred_imgs = []\n",
    "        # add first 11 frames to both\n",
    "        for t in range(x.shape[0]):\n",
    "            gt_imgs.append(self.apply_cm(x[t]))\n",
    "            pred_imgs.append(self.apply_cm(x[t]))\n",
    "        \n",
    "        # add ground truth and predictions\n",
    "        for t in range(y.shape[0]):\n",
    "            gt_imgs.append(self.apply_cm(y[t]))\n",
    "            pred_imgs.append(self.apply_cm(y_hat[t]))\n",
    "        \n",
    "        gt_imgs = np.stack(gt_imgs, axis=0)\n",
    "        pred_imgs = np.stack(pred_imgs, axis=0)\n",
    "        video = (np.concatenate([gt_imgs, pred_imgs], axis=-1) * 255).astype(np.uint8)\n",
    "        return video\n",
    "    \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        video = self.generate_video(pl_module)\n",
    "        trainer.logger.experiment.log({\n",
    "            \"val_video\": wandb.Video(video, fps=4, format=\"gif\")\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
